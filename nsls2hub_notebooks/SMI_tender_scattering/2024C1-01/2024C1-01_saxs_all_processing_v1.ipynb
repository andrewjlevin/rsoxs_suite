{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Processing notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PyHyperScattering as phs\n",
    "import pathlib\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "import fabio\n",
    "from smi_analysis import SMI_beamline\n",
    "\n",
    "print(phs.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define paths & functions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4",
   "metadata": {},
   "source": [
    "Raw text paths for the purpose of pasting into terminal to copy/move/zip data:\n",
    "\n",
    "Raw Paths:\n",
    "/nsls2/data/smi/legacy/results/data/2024_1/314903_Chaney_01  # solution\n",
    "/nsls2/data/smi/legacy/results/data/2024_1/314903_Chaney_02  # films normal incidence\n",
    "/nsls2/data/smi/legacy/results/data/2024_1/314903_Chaney_03  # solution\n",
    "/nsls2/data/smi/legacy/results/data/2024_1/314903_Chaney_04  # films measured at angle 0, \n",
    "\n",
    "SMI Analysis Data Paths:\n",
    "/nsls2/data/smi/legacy/results/analysis/2024_1/314903_Chaney_01\n",
    "/nsls2/data/smi/legacy/results/analysis/2024_1/314903_Chaney_02\n",
    "/nsls2/data/smi/legacy/results/analysis/2024_1/314903_Chaney_03  # empty\n",
    "/nsls2/data/smi/legacy/results/analysis/2024_1/314903_Chaney_04\n",
    "\n",
    "Our proposal path:\n",
    "/nsls2/data/smi/proposals/2024-1/pass-314903\n",
    "\n",
    "Rclone copy statement to paste:\n",
    "rclone copy -LP /nsls2/data/smi/legacy/results/data/2024_1/314903_Chaney_04 /nsls2/data/smi/proposals/2024-1/pass-314903/raw_04\n",
    "rclone copy -LP /nsls2/data/smi/legacy/results/analysis/2024_1/314903_Chaney_04 ./analysis_04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_name_dict = {\n",
    "    14: 'PM6_CB',\n",
    "    17: 'PM6_1CN-CB',\n",
    "    18: 'PM6_5CN-CB',\n",
    "    21: 'PM6_p5CN-CB',\n",
    "    22: 'PM6-Y6_CB',\n",
    "    23: 'PM6-Y6BO_CB',\n",
    "    26: 'PM6_CF',\n",
    "    29: 'PM6_1CN-CF',\n",
    "    30: 'PM6_5CN-CF',\n",
    "    33: 'PM6_p5CN-CF',\n",
    "    34: 'PM6-Y6_CF',\n",
    "    35: 'PM6-Y6BO_CF',\n",
    "    1: 'BareSiN_01',\n",
    "    3: 'BareSiN_03'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "propPath = pathlib.Path('/nsls2/data/smi/proposals/2024-1/pass-314903')\n",
    "\n",
    "rawPaths1 = propPath.joinpath('raw_01')\n",
    "saxsPath1 = rawPaths1.joinpath('1M')\n",
    "waxsPath1 = rawPaths1.joinpath('900KW')\n",
    "\n",
    "rawPaths2 = propPath.joinpath('raw_02')\n",
    "saxsPath2 = rawPaths2.joinpath('1M')\n",
    "waxsPath2 = rawPaths2.joinpath('900KW')\n",
    "\n",
    "rawPaths3 = propPath.joinpath('raw_03')\n",
    "saxsPath3 = rawPaths3.joinpath('1M')\n",
    "waxsPath3 = rawPaths3.joinpath('900KW')\n",
    "\n",
    "rawPaths4 = propPath.joinpath('raw_04')\n",
    "saxsPath4 = rawPaths4.joinpath('1M')\n",
    "waxsPath4 = rawPaths4.joinpath('900KW')\n",
    "\n",
    "# analysisPath = pathlib.Path('/nsls2/users/alevin/rsoxs_suite/sst1_notebooks/SMI_tender_scattering/analysis_02')\n",
    "# reducedPath = analysisPath.joinpath('reduced_waxs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# solnPaths = [saxsPath1, saxsPath3]\n",
    "# filmPaths = [saxsPath2, saxsPath4]\n",
    "# # for saxsPath in solnPaths:\n",
    "# #     all_saxs = set(saxsPath.glob('*.tif'))\n",
    "# #     test_saxs = set(saxsPath.glob('test*'))\n",
    "# #     display(sorted(set([f.name[:f.name.find('_sdd1.8')] for f in all_saxs.difference(test_saxs)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SMI loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#waxs\n",
    "path = '/nsls2/data/smi/legacy/results/data/%s/%s/1M/'%('2024_1', '314483_Freychet_12')\n",
    "\n",
    "sam, sam1 = [], []\n",
    "for file in sorted(os.listdir(path)):\n",
    "     if 'wa0' in file and 'ai1.60' in file and '2800.00eV' in file:\n",
    "        idx = file.find('pos')\n",
    "        if file[:idx] not in sam:\n",
    "            sam = sam + [file[:idx]]\n",
    "\n",
    "all_dat = [[]] * len(sam)\n",
    "all_da = [[]] * len(sam)\n",
    "    \n",
    "for j, sa in enumerate(sam): \n",
    "    for file in sorted(os.listdir(path)):\n",
    "        if sa in file and 'tif' in file and 'ai1.60' in file:\n",
    "            all_dat[j] = all_dat[j] + [file]\n",
    "            \n",
    "for i, all_d in enumerate(all_dat[0]):\n",
    "    img=fabio.open(os.path.join(path, all_d)).data\n",
    "    if i==0:\n",
    "        img_sum=np.zeros(np.shape(img))\n",
    "    img_sum += img\n",
    "\n",
    "idx_mask = np.where(img_sum>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def saxs_SMI_numpy_loading(path, filename_list):\n",
    "    \"\"\"\n",
    "    Function adapted from Guillames SMI notebooks to process raw waxs tiffs:\n",
    "    \n",
    "    Returns filename_wa0_list, recip_list, recip_extents, caked_list, caked_extents\n",
    "    \"\"\"\n",
    "    \n",
    "    #Saxs\n",
    "    geometry = 'Transmission'\n",
    "    energy = 2.450\n",
    "    wav = 1E-10 * (12.398/energy)\n",
    "    bs_kind = 'pindiode'\n",
    "    alphai = np.deg2rad(0)\n",
    "\n",
    "    #SAXS\n",
    "    detector_waxs = 'Pilatus1m'\n",
    "    sdd_waxs = 1800\n",
    "    center_waxs = [354, 560]\n",
    "    bs_pos_waxs = [[354, 535]]\n",
    "    \n",
    "    # flatPath = pathlib.Path('/nsls2/data/smi/legacy/results/analysis/2024_1/314483_Freychet_04')\n",
    "    # flatfield = np.rot90(fabio.open(flatPath.joinpath('GF_Flatfield_Sedge_uhighg1600eV_10s_wa20_2477eV_pffBT4T_id481136_000000_WAXS.tif')).data, 1)\n",
    "\n",
    "    \n",
    "    filename_wa0_list = []\n",
    "    recip_list = []\n",
    "    recip_extents = []\n",
    "    caked_list = []\n",
    "    caked_extents = []\n",
    "    for dat in tqdm(filename_list, desc='Processing tiffs'):\n",
    "        \n",
    "#             waxs_angle = [np.deg2rad(-0.06), np.deg2rad(19.7-0.06)]\n",
    "#             # print(dat)\n",
    "\n",
    "#             idx = dat[0].find('eV')\n",
    "#             energy = 0.001*float(dat[0][idx-7:idx])\n",
    "#             # print(energy)\n",
    "#             wav = 1E-10 * (12.398/energy)\n",
    "\n",
    "            #This part is to stitch the data\n",
    "            SMI_waxs = SMI_beamline.SMI_geometry(geometry = geometry,\n",
    "                                                 detector = detector_waxs,\n",
    "                                                 sdd = sdd_waxs,\n",
    "                                                 wav = wav,\n",
    "                                                 alphai = 0,\n",
    "                                                 center = center_waxs,\n",
    "                                                 bs_pos = bs_pos_waxs,\n",
    "                                                 det_angles = [0],\n",
    "                                                 bs_kind = bs_kind)\n",
    "\n",
    "\n",
    "            # print(dat)\n",
    "            SMI_waxs.open_data(path, [dat], optional_mask='tender')\n",
    "            SMI_waxs.masks[0][560:, 337:350]=True\n",
    "            \n",
    "            for da in [dat]:\n",
    "                img=fabio.open(os.path.join(path, da)).data\n",
    "                SMI_waxs.imgs[0]+=img\n",
    "\n",
    "            SMI_waxs.masks[0][idx_mask]=True\n",
    "            SMI_waxs.masks[0][570:, 337:342]=True\n",
    "\n",
    "            SMI_waxs.masks[0][835:, 488:616]=True\n",
    "            SMI_waxs.masks[0][372:414, 857:920]=True\n",
    "            SMI_waxs.masks[0][370:410, 560:600]=True\n",
    "\n",
    "            SMI_waxs.stitching_data(interp_factor=3, flag_scale=False)\n",
    "            SMI_waxs.caking()\n",
    "            \n",
    "            filename_wa0_list.append(dat)\n",
    "            recip_list.append(SMI_waxs.img_st)\n",
    "            recip_extents.append([SMI_waxs.qp[0], SMI_waxs.qp[-1], SMI_waxs.qz[0], SMI_waxs.qz[-1]])\n",
    "            \n",
    "            caked_list.append(SMI_waxs.cake)\n",
    "            caked_extents.append([SMI_waxs.q_cake[0], SMI_waxs.q_cake[-1], SMI_waxs.chi_cake[0], SMI_waxs.chi_cake[-1]])\n",
    "            \n",
    "    return filename_wa0_list, recip_list, recip_extents, caked_list, caked_extents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_sample_numbers = sorted(set([f.name.split('_')[2] for f in saxsPath4.glob('*')]))\n",
    "unique_sample_rotations = sorted(set([f.name.split('_')[3] for f in saxsPath4.glob('*')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_saxs = set(saxsPath4.glob('*.tif'))\n",
    "# test_saxs = set(saxsPath4.glob('test*'))\n",
    "sample_names = sorted(set([f.name[3:f.name.find('_sdd1.8')] for f in all_saxs]))\n",
    "sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filename_sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample_number in tqdm(unique_sample_numbers[1:], desc='Samples'):\n",
    "    for sample_rotation in tqdm(unique_sample_rotations, desc='Angles'):\n",
    "\n",
    "        # Select files for a given sample and rotation\n",
    "        all_paths = set(saxsPath4.glob(f'*Trmsn_{sample_number}*{sample_rotation}*'))\n",
    "        dmg_paths = set(saxsPath4.glob(f'*Trmsn_{sample_number}*{sample_rotation}*damage*'))\n",
    "        \n",
    "        # For now only select first scans, not the damage test repeats\n",
    "        filename_list = [f.name for f in sorted(all_paths.difference(dmg_paths))]\n",
    "\n",
    "        # Run SMI loading code (this produces some fabio and divide by zero errors)\n",
    "        names_list, recip_list, recip_extents, caked_list, caked_extents = saxs_SMI_numpy_loading(saxsPath4, filename_list)\n",
    "\n",
    "        # Define naming scheme:\n",
    "        waxs_naming_scheme = ['project', 'sample_type', 'sample_number', 'rotation_from_normal', 'set_sdd', 'energy', 'waxs_det_position',\n",
    "                              'bpm', 'id', 'misc', 'detector']\n",
    "        md_naming_scheme = waxs_naming_scheme.copy()\n",
    "\n",
    "\n",
    "        # Construct xarrays with full values along detector dimensions and the energy dimension\n",
    "        # They contain sample name and theta value as well, as single values to be concatenated in later steps\n",
    "        recip_DA_rows = []\n",
    "        caked_DA_rows = []\n",
    "        zipped_lists = zip(names_list, recip_list, recip_extents, caked_list, caked_extents)\n",
    "        for filename, recip_arr, recip_extent, caked_arr, caked_extent in zipped_lists:\n",
    "            # print(filename)\n",
    "            # print(recip_arr.shape)\n",
    "            # print(recip_extent)\n",
    "            # print(caked_arr.shape)\n",
    "            # print(caked_extent)\n",
    "\n",
    "            attr_dict = {}\n",
    "            md_list = filename.split('_')\n",
    "            for i, md_item in enumerate(md_naming_scheme):\n",
    "                attr_dict[md_item] = md_list[i]\n",
    "\n",
    "            recip_DA = xr.DataArray(data = recip_arr, \n",
    "                                    dims = ['pix_y', 'pix_x'],\n",
    "                                    attrs = attr_dict)\n",
    "            recip_DA = recip_DA.assign_coords({\n",
    "                'pix_x': recip_DA.pix_x.data,\n",
    "                'pix_y': recip_DA.pix_y.data,\n",
    "                'q_x': ('pix_x', np.linspace(recip_extent[0], recip_extent[1], len(recip_DA.pix_x.data))),\n",
    "                'q_y': ('pix_y', np.linspace(recip_extent[3], recip_extent[2], len(recip_DA.pix_y.data)))\n",
    "            })\n",
    "            recip_DA = recip_DA.expand_dims({\n",
    "                'energy': [float(recip_DA.energy[:-2])],\n",
    "                'sample_name': [sample_name_dict[float(recip_DA.sample_number)]],\n",
    "                'theta': [90 - float(recip_DA.rotation_from_normal[3:-3])]\n",
    "            })\n",
    "            recip_DA_rows.append(recip_DA)\n",
    "\n",
    "            caked_DA = xr.DataArray(data = caked_arr, \n",
    "                                    dims = ['index_y', 'index_x'],\n",
    "                                    attrs = attr_dict)\n",
    "            caked_DA = caked_DA.assign_coords({\n",
    "                'index_x': caked_DA.index_x.data,\n",
    "                'index_y': caked_DA.index_y.data,\n",
    "                'q_r': ('index_x', np.linspace(caked_extent[0], caked_extent[1], len(caked_DA.index_x.data))),\n",
    "                'chi': ('index_y', np.linspace(caked_extent[3], caked_extent[2], len(caked_DA.index_y.data)))\n",
    "            }) \n",
    "            caked_DA = caked_DA.expand_dims({\n",
    "                'energy': [float(caked_DA.energy[:-2])],\n",
    "                'sample_name': [sample_name_dict[float(caked_DA.sample_number)]],\n",
    "                'theta': [90 - float(caked_DA.rotation_from_normal[3:-3])]\n",
    "            })\n",
    "            caked_DA_rows.append(caked_DA)\n",
    "\n",
    "        recip_DA = xr.concat(recip_DA_rows, 'energy')\n",
    "        caked_DA = xr.concat(caked_DA_rows, 'energy')\n",
    "\n",
    "        # Save sample zarr, load later to concatenate full zarr\n",
    "        sampleZarrsPath = propPath.joinpath('processed_data/zarrs/saxs_core_films_trexs_sample_zarrs_v2')\n",
    "\n",
    "        recip_samp_zarr_name = 'recip_'+recip_DA.sample_name.values[0]+'_'+str(int(recip_DA.theta.values[0]))+'deg.zarr'\n",
    "        recip_DS = recip_DA.to_dataset(name='flatfield_corr')\n",
    "        recip_DS.to_zarr(sampleZarrsPath.joinpath(recip_samp_zarr_name), mode='w')\n",
    "\n",
    "        caked_samp_zarr_name = 'caked_'+caked_DA.sample_name.values[0]+'_'+str(int(caked_DA.theta.values[0]))+'deg.zarr'\n",
    "        caked_DS = caked_DA.to_dataset(name='flatfield_corr')\n",
    "        caked_DS.to_zarr(sampleZarrsPath.joinpath(caked_samp_zarr_name), mode='w')\n",
    "        \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recip_DA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_saxs = set(saxsPath1.glob('*.tif'))\n",
    "test_saxs = set(saxsPath1.glob('test*'))\n",
    "sample_names = sorted(set([f.name[3:f.name.find('_sdd1.8')] for f in all_saxs.difference(test_saxs)]))\n",
    "sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "saxs_63 = []\n",
    "\n",
    "print('Before:')\n",
    "for sample_name in sample_names[:-1]:\n",
    "    files = sorted(saxsPath1.glob(f'CM_{sample_name}_sdd*'))\n",
    "    files_number = len(files)\n",
    "    print(files_number)\n",
    "    if files_number == 63:\n",
    "        saxs_63.append(files)\n",
    "    else:\n",
    "        file_energies = []\n",
    "        kept_files = []\n",
    "\n",
    "        for file in files:\n",
    "            file_energy = file.name[:file.name.find('eV')].split('_')[-1]\n",
    "            if file_energy in file_energies:\n",
    "                pass\n",
    "            else:\n",
    "                file_energies.append(file_energy)\n",
    "                kept_files.append(file)\n",
    "\n",
    "        saxs_63.append(kept_files)  \n",
    "\n",
    "print('After (in saxs_63):')\n",
    "for i in range(len(saxs_63)):\n",
    "    print(len(saxs_63[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update sample names\n",
    "\n",
    "sample_names = []\n",
    "for folder in saxs_63:\n",
    "    sample_name = folder[0].name[3:folder[0].name.find('_sdd1.8')]\n",
    "    sample_names.append(sample_name)\n",
    "\n",
    "display(sample_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make file sets & define unique sample names\n",
    "for i, sample_name in enumerate(tqdm(sample_names, desc='Samples')):\n",
    "    # Select files for a given sample and rotation\n",
    "    # all_paths = set(saxsPath.glob(f'*_{sample_name}_*'))\n",
    "    all_paths = saxs_63[i]\n",
    "    \n",
    "    # Select first scans\n",
    "    filename_list = [f.name for f in sorted(all_paths)]\n",
    "\n",
    "    # # Make sublists to stitch two waxs positions together\n",
    "    # group_size = 2\n",
    "    # filename_sublists = [filename_list[i:i + group_size] for i in range(0, len(filename_list), group_size)]\n",
    "\n",
    "    # Run SMI loading code (this produces some fabio and divide by zero errors)\n",
    "    names_list, recip_list, recip_extents, caked_list, caked_extents = saxs_SMI_numpy_loading(\n",
    "        saxsPath1, filename_list)\n",
    "\n",
    "    # # Define naming scheme:\n",
    "    # saxs_naming_scheme = ['project', 'sample_type', 'sample_number', 'rotation_from_normal', 'set_sdd', 'energy', 'waxs_det_position',\n",
    "    #                       'bpm', 'id', 'misc', 'detector']\n",
    "    # md_naming_scheme = saxs_naming_scheme.copy()\n",
    "\n",
    "\n",
    "    # Construct xarrays with full values along detector dimensions and the energy dimension\n",
    "    # They contain sample name and theta value as well, as single values to be concatenated in later steps\n",
    "    recip_DA_rows = []\n",
    "    caked_DA_rows = []\n",
    "    zipped_lists = zip(names_list, recip_list, recip_extents, caked_list, caked_extents)\n",
    "    for filename, recip_arr, recip_extent, caked_arr, caked_extent in zipped_lists:\n",
    "        # print(filename)\n",
    "        # print(recip_arr.shape)\n",
    "        # print(recip_extent)\n",
    "        # print(caked_arr.shape)\n",
    "        # print(caked_extent)\n",
    "\n",
    "        attr_dict = {}\n",
    "        attr_dict['filename'] = filename\n",
    "        sample_name = filename[3:filename.find('_sdd')]\n",
    "        energy = float(filename[:filename.find('eV')].split('_')[-1])\n",
    "        # md_list = filename.split('_')\n",
    "        # for i, md_item in enumerate(md_naming_scheme):\n",
    "        #     attr_dict[md_item] = md_list[i]\n",
    "\n",
    "        recip_DA = xr.DataArray(data = recip_arr, \n",
    "                                dims = ['pix_y', 'pix_x'],\n",
    "                                attrs = attr_dict)\n",
    "        recip_DA = recip_DA.assign_coords({\n",
    "            'pix_x': recip_DA.pix_x.data,\n",
    "            'pix_y': recip_DA.pix_y.data,\n",
    "            'q_x': ('pix_x', np.linspace(recip_extent[0], recip_extent[1], len(recip_DA.pix_x.data))),\n",
    "            'q_y': ('pix_y', np.linspace(recip_extent[3], recip_extent[2], len(recip_DA.pix_y.data)))\n",
    "        })\n",
    "        recip_DA = recip_DA.expand_dims({\n",
    "            'energy': [energy],\n",
    "            'sample_name': [sample_name]\n",
    "        })\n",
    "        recip_DA_rows.append(recip_DA)\n",
    "\n",
    "        caked_DA = xr.DataArray(data = caked_arr, \n",
    "                                dims = ['index_y', 'index_x'],\n",
    "                                attrs = attr_dict)\n",
    "        caked_DA = caked_DA.assign_coords({\n",
    "            'index_x': caked_DA.index_x.data,\n",
    "            'index_y': caked_DA.index_y.data,\n",
    "            'q_r': ('index_x', np.linspace(caked_extent[0], caked_extent[1], len(caked_DA.index_x.data))),\n",
    "            'chi': ('index_y', np.linspace(caked_extent[3], caked_extent[2], len(caked_DA.index_y.data)))\n",
    "        }) \n",
    "        caked_DA = caked_DA.expand_dims({\n",
    "            'energy': [energy],\n",
    "            'sample_name': [sample_name]\n",
    "        })\n",
    "        caked_DA_rows.append(caked_DA)\n",
    "\n",
    "    recip_DA = xr.concat(recip_DA_rows, 'energy')\n",
    "    caked_DA = xr.concat(caked_DA_rows, 'energy')\n",
    "\n",
    "    # Save sample zarr, load later to concatenate full zarr\n",
    "    sampleZarrsPath = propPath.joinpath('processed_data/saxs_solution_trexs_sample_zarrs_v2')\n",
    "\n",
    "    recip_samp_zarr_name = 'recip_'+sample_name+'.zarr'\n",
    "    recip_DS = recip_DA.to_dataset(name='flatfield_corr')\n",
    "    recip_DS.to_zarr(sampleZarrsPath.joinpath(recip_samp_zarr_name), mode='w')\n",
    "\n",
    "    caked_samp_zarr_name = 'caked_'+sample_name+'.zarr'\n",
    "    caked_DS = caked_DA.to_dataset(name='flatfield_corr')\n",
    "    caked_DS.to_zarr(sampleZarrsPath.joinpath(caked_samp_zarr_name), mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Draw/check data & beamcenters & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "propPath = pathlib.Path('/nsls2/data/smi/proposals/2024-1/pass-314903')\n",
    "outPath = propPath.joinpath('processed_data/trexs_plots')\n",
    "sampleZarrsPath = propPath.joinpath('processed_data/zarrs/saxs_core_films_trexs_sample_zarrs')\n",
    "\n",
    "# rawPaths = propPath.joinpath('raw_04')\n",
    "# waxsPath = rawPaths.joinpath('900KW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampleZarrsPath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_sample_names = sorted(set(['_'.join(f.name.split('_')[1:3]) for f in sampleZarrsPath.glob('*')]))\n",
    "unique_sample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recip_DS_rows = []\n",
    "# caked_DS_rows = []\n",
    "for sample_name in tqdm(unique_sample_names):\n",
    "    sample_zarrs = sorted(sampleZarrsPath.glob(f'*{sample_name}*'))\n",
    "    # display(sorted([f.name for f in sample_zarrs]))\n",
    "    \n",
    "    samp_recip_DS_rows = []\n",
    "    # samp_caked_DS_rows = []\n",
    "    for sample_zarr in sample_zarrs:\n",
    "        if 'recip_' in sample_zarr.name:\n",
    "            recip_DS = xr.open_zarr(sample_zarr)\n",
    "            samp_recip_DS_rows.append(recip_DS)\n",
    "        # elif 'caked_' in sample_zarr.name:\n",
    "        #     caked_DS = xr.open_zarr(sample_zarr)\n",
    "        #     samp_caked_DS_rows.append(caked_DS)\n",
    "            \n",
    "    recip_DS = xr.concat(samp_recip_DS_rows, 'theta')\n",
    "    recip_DS_rows.append(recip_DS)\n",
    "    \n",
    "    # caked_DS = xr.concat(samp_caked_DS_rows, 'theta')\n",
    "    # caked_DS_rows.append(caked_DS)\n",
    "    \n",
    "recip_DS = xr.concat(recip_DS_rows, 'sample_name')\n",
    "# caked_DS = xr.concat(caked_DS_rows, 'sample_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recip_DS = recip_DS.chunk({'sample_name':1, 'pix_y': 3129, 'pix_x': 2943, 'energy':63,})\n",
    "# caked_DS = caked_DS.chunk({'sample_name':1, 'index_y':500,'index_x':500,'energy':63})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# recip_DS = recip_DS.swap_dims({'pix_y':'q_y', 'pix_x':'q_x'})\n",
    "# caked_DS = caked_DS.swap_dims({'index_y':'chi', 'index_x':'q_r'})\n",
    "recip_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_para_perp_DAs(DS, sample_name, theta=90, chi_width=90):\n",
    "    # select dataarray to plot\n",
    "    DA = DS.sel(sample_name=sample_name)['flatfield_corr']\n",
    "    sel_DA = DA.sel(theta=theta)\n",
    "\n",
    "    # calculate ISI dataarrays\n",
    "    para_DA = sel_DA.rsoxs.slice_chi(0, chi_width=(chi_width/2))\n",
    "    perp_DA = sel_DA.rsoxs.slice_chi(-90, chi_width=(chi_width/2))\n",
    "        \n",
    "    return para_DA, perp_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set colormap\n",
    "cmap = plt.cm.turbo.copy()\n",
    "cmap.set_bad(cmap.get_under())\n",
    "\n",
    "# # Choose a sample dataarray:\n",
    "# bare_sin_DA = DS.sel(sample_name='BareSiN_1mm')\n",
    "# print(DS.sample_name.values)\n",
    "# sample_name = 'Y6_CB_2500'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Check raw images at a selected energy for all loaded scan configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS = recip_DS\n",
    "\n",
    "# sample_name = 'PM6_5CN-CB'\n",
    "# sample_DA = DS['raw_intensity'].sel(sample_name=sample_name)\n",
    "# # sample_DA = loaded_DS['raw_intensity'].sel(sample_name=sample_name)\n",
    "\n",
    "\n",
    "# fg = sample_DA.sel(polarization=pol, method='nearest').sel(energy=energies, method='nearest').sel(\n",
    "#             pix_x=slice(160, 780), pix_y=slice(240, 800)).plot.imshow(figsize=(18, 6),\n",
    "#                 col='energy', col_wrap=4, norm=LogNorm(3e1, 1e4), cmap=cmap, x='qx', y='qy')\n",
    "# fg.cbar.set_label('Intensity [arb. units]', rotation=270, labelpad=15)\n",
    "# fg.fig.suptitle(f'{str(sample_DA.sample_name.data)},  Polarization = {pol}°', y=1.02)\n",
    "# for axes in fg.axs.flatten():\n",
    "#     axes.set(aspect='equal')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_name = 'PM6-Y6BO_CF'\n",
    "# corr_sample_DA = DS['corr_intensity'].sel(sample_name=sample_name)\n",
    "\n",
    "# # energies = [270, 280, 282, 283, 284, 285, 286, 290]\n",
    "# energies = np.round(np.linspace(280, 290, 8), 1)  # carbon\n",
    "# # energies = np.round(np.linspace(380, 440, 8), 1)  # nitrogen\n",
    "\n",
    "# pol = 0\n",
    "\n",
    "# fg = corr_sample_DA.sel(polarization=pol, method='nearest').sel(energy=energies, method='nearest').sel(\n",
    "#             pix_x=slice(160, 780), pix_y=slice(240, 800)).plot.imshow(figsize=(18, 6), x='qx', y='qy',\n",
    "#                 col='energy', col_wrap=4, norm=LogNorm(5e8, 1e11), cmap=cmap)\n",
    "# fg.cbar.set_label('Intensity [arb. units]', rotation=270, labelpad=15)\n",
    "# fg.fig.suptitle(f'{str(sample_name)},  Polarization = {pol}°', y=1.02)\n",
    "# for axes in fg.axs.flatten():\n",
    "#     axes.set(aspect='equal')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Draw masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example image for mask & initialize phs DrawMask object:\n",
    "sample_name = 'BareSiN_01'\n",
    "sample_DA = recip_DS['flatfield_corr'].sel(sample_name=sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## WAXS mask:\n",
    "waxs_mask_img = sample_DA.sel(theta=90, energy=2550, method='nearest').compute()\n",
    "# draw = phs.IntegrationUtils.DrawMask(waxs_mask_img, clim=(30, 1e3))\n",
    "draw = phs.IntegrationUtils.DrawMask(waxs_mask_img)\n",
    "\n",
    "draw.ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save and load saxs drawn mask\n",
    "draw.save(outPath.joinpath('SMI_saxs_mask_v1_test.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Check beamcenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example image for mask & initialize phs DrawMask object:\n",
    "sample_name = 'PM6-Y6BO_CF'\n",
    "sample_DA = DS['raw_intensity'].sel(sample_name=sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_DA.attrs['beamcenter_x'] = 450\n",
    "# sample_DA.attrs['beamcenter_y'] = 510\n",
    "\n",
    "energy = 250\n",
    "# energy = 400\n",
    "# energy = 532\n",
    "\n",
    "waxs_mask_img = sample_DA.sel(polarization=0, energy=energy, method='nearest').compute()\n",
    "draw = phs.IntegrationUtils.DrawMask(waxs_mask_img)\n",
    "\n",
    "# Load masks:\n",
    "draw.load(maskPath.joinpath('2023C3_full_length_masks.json'))\n",
    "waxs_mask = draw.mask\n",
    "\n",
    "# Check masks:\n",
    "ax = waxs_mask_img.plot.imshow(norm=LogNorm(3e1, 1e4), cmap=cmap)\n",
    "ax.axes.imshow(waxs_mask, alpha=0.5, origin='lower')\n",
    "# ax.axes.imshow(WAXSinteg.mask, alpha=0.5, origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initalize PFEnergySeriesIntegrator object & check beamcenter & masks\n",
    "# WAXS\n",
    "WAXSinteg = phs.integrate.PFEnergySeriesIntegrator(geomethod='template_xr', template_xr=sample_DA.sel(polarization=0))\n",
    "WAXSinteg.mask = waxs_mask\n",
    "WAXSinteg.ni_beamcenter_x = waxs_mask_img.beamcenter_x\n",
    "WAXSinteg.ni_beamcenter_y = waxs_mask_img.beamcenter_y\n",
    "print('WAXS Beamcenter: \\n'\n",
    "      f'poni1: {WAXSinteg.poni1}, poni2: {WAXSinteg.poni2} \\n'\n",
    "      f'ni_beamcenter_y: {WAXSinteg.ni_beamcenter_y}, ni_beamcenter_x: {WAXSinteg.ni_beamcenter_x}')\n",
    "\n",
    "# Plot check\n",
    "phs.IntegrationUtils.Check.checkAll(WAXSinteg, waxs_mask_img, img_max=1e4, alpha=0.5)\n",
    "plt.xlim(WAXSinteg.ni_beamcenter_x-250, WAXSinteg.ni_beamcenter_x+250)\n",
    "plt.ylim(WAXSinteg.ni_beamcenter_y-250, WAXSinteg.ni_beamcenter_y+250)\n",
    "plt.gcf().set(dpi=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Tweaking if needed:\n",
    "\n",
    "# ## WAXS Tweaking & Plot Check\n",
    "# waxs_new_bcx = 396.3\n",
    "# waxs_new_bcy = 553\n",
    "# WAXSinteg.ni_beamcenter_x = waxs_new_bcx\n",
    "# WAXSinteg.ni_beamcenter_y = waxs_new_bcy\n",
    "# raw_waxs.attrs['beamcenter_x'] = waxs_new_bcx\n",
    "# raw_waxs.attrs['beamcenter_x'] = waxs_new_bcx\n",
    "# raw_waxs.attrs['poni1'] = WAXSinteg.poni1\n",
    "# raw_waxs.attrs['poni2'] = WAXSinteg.poni2\n",
    "\n",
    "# print('WAXS Beamcenter Tweaking: \\n'\n",
    "#       f'poni1: {WAXSinteg.poni1}, poni2: {WAXSinteg.poni2} \\n'\n",
    "#       f'ni_beamcenter_y: {WAXSinteg.ni_beamcenter_y}, ni_beamcenter_x: {WAXSinteg.ni_beamcenter_x}')\n",
    "# phs.IntegrationUtils.Check.checkAll(WAXSinteg, waxs_mask_img, img_max=5e3, alpha=0.6, guide1=40)\n",
    "# plt.xlim(WAXSinteg.ni_beamcenter_x-200, WAXSinteg.ni_beamcenter_x+200)\n",
    "# plt.ylim(WAXSinteg.ni_beamcenter_y-200, WAXSinteg.ni_beamcenter_y+200)\n",
    "# plt.gcf().set(dpi=120)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "## Using Pete D.'s (very slightly modified) beamcentering script:\n",
    "# phs.BeamCentering.CenteringAccessor.refine_geometry\n",
    "\n",
    "# ## WAXS\n",
    "# # res_waxs = raw_waxs.sel(pol=0).util.refine_geometry(energy=275, q_min=0.02, q_max=0.06, chi_min=-10, chi_max=70)\n",
    "# res_waxs = sample_DA.sel(polarization=0).util.refine_geometry(energy=270, q_min=0.02, q_max=0.06)\n",
    "# sample_DA.attrs['poni1'] = res_waxs.x[0]\n",
    "# sample_DA.attrs['poni2'] = res_waxs.x[1]\n",
    "# WAXSinteg = phs.integrate.PFEnergySeriesIntegrator(geomethod='template_xr', template_xr = sample_DA.sel(polarization=0))\n",
    "# WAXSinteg.mask = waxs_mask\n",
    "\n",
    "# ## WAXS Plot check\n",
    "# print('WAXS Beamcenter Post-optimization: \\n'\n",
    "#       f'poni1: {WAXSinteg.poni1}, poni2: {WAXSinteg.poni2} \\n'\n",
    "#       f'ni_beamcenter_y: {WAXSinteg.ni_beamcenter_y}, ni_beamcenter_x: {WAXSinteg.ni_beamcenter_x}')\n",
    "# phs.IntegrationUtils.Check.checkAll(WAXSinteg, waxs_mask_img, img_max=1e5, alpha=0.4)\n",
    "# plt.xlim(WAXSinteg.ni_beamcenter_x-100, WAXSinteg.ni_beamcenter_x+100)\n",
    "# plt.ylim(WAXSinteg.ni_beamcenter_y-100, WAXSinteg.ni_beamcenter_y+100)\n",
    "# plt.gcf().set(dpi=120)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### Write beamcenters to saved .json file if content with them:\n",
    "\n",
    "# beamcenters_dict = {\n",
    "#     f'WAXS_2023C2': {'bcx':sample_DA.beamcenter_x, 'bcy':sample_DA.beamcenter_y}\n",
    "# }\n",
    "\n",
    "# # Check if the file exists, if not, create an empty JSON file\n",
    "# jsonFile = jsonPath.joinpath('beamcenters_dict.json')\n",
    "# if not jsonFile.exists():\n",
    "#     with jsonFile.open('w') as f:\n",
    "#         json.dump({}, f)\n",
    "\n",
    "# # Now, read the existing or empty JSON file\n",
    "# with jsonFile.open('r') as f:\n",
    "#     dic = json.load(f)\n",
    "\n",
    "# dic.update(beamcenters_dict)\n",
    "\n",
    "# # Write the updated dictionary back to the JSON file\n",
    "# with jsonFile.open('w') as f:\n",
    "#     json.dump(dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make mask DataArray:\n",
    "# mask_DA = xr.DataArray(data=waxs_mask, dims=['pix_y', 'pix_x'])\n",
    "\n",
    "# # Create Dataset of rsoxs_carbon and add the mask as a data variable\n",
    "# DS = DA.to_dataset()\n",
    "# DS['mask'] = mask_DA\n",
    "# display(DS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Convert to chi-q space & save zarrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Integrate whole cartesian dataset!\n",
    "polar_DS_sample_rows = []\n",
    "for sample_name in tqdm(DS.sample_name.data):\n",
    "# for sample_name in tqdm(['BareSiN', 'A3_3000_dSiN_01', 'BareAlO', 'PM6_3000_dSiN', 'PM6-Y7_3000_dSiN']):\n",
    "    polar_DS = xr.Dataset()\n",
    "    for intensity in ['corr_intensity']:\n",
    "        polar_DA_polarization_rows = []\n",
    "        for pol in [0, 90]:\n",
    "            cart_DA = DS[intensity].sel(polarization=pol, sample_name=sample_name)\n",
    "            polar_DA = WAXSinteg.integrateImageStack_dask(cart_DA)\n",
    "            # polar_DA = WAXSinteg.integrateImageStack(cart_DA)\n",
    "            polar_DA = polar_DA.expand_dims({'polarization': [pol]})\n",
    "            polar_DA_polarization_rows.append(polar_DA)\n",
    "        \n",
    "        polar_DS[intensity] = xr.concat(polar_DA_polarization_rows, dim='polarization')\n",
    "\n",
    "    polar_DS = polar_DS.expand_dims({'sample_name':[sample_name]})\n",
    "    polar_DS_sample_rows.append(polar_DS)\n",
    "    polar_DS.attrs['name'] = DS.name\n",
    "    \n",
    "    # polar_DS.to_netcdf(zarrsPath.joinpath('polar_rsoxs_carbon_ncs', f'{sample_name}.nc'), format='netCDF4', engine='h5netcdf')\n",
    "    \n",
    "polar_DS = xr.concat(polar_DS_sample_rows, dim='sample_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_para_perp_DAs(DS, sample_name, intensity_type, pol, qlims, chi_width):\n",
    "    # select dataarray to plot\n",
    "    DA = DS.sel(sample_name=sample_name)[f'{intensity_type}_intensity']\n",
    "    sliced_DA = DA.sel(polarization=pol, q=slice(qlims[0],qlims[1]))\n",
    "\n",
    "    # calculate ISI dataarrays\n",
    "    if pol==0:\n",
    "        para_DA = sliced_DA.rsoxs.slice_chi(180, chi_width=(chi_width/2))\n",
    "        perp_DA = sliced_DA.rsoxs.slice_chi(90, chi_width=(chi_width/2))\n",
    "    elif pol==90:\n",
    "        perp_DA = sliced_DA.rsoxs.slice_chi(180, chi_width=(chi_width/2))\n",
    "        para_DA = sliced_DA.rsoxs.slice_chi(90, chi_width=(chi_width/2))   \n",
    "        \n",
    "    return para_DA, perp_DA\n",
    "\n",
    "\n",
    "# # make selection\n",
    "# sample_name = 'BareSiN'\n",
    "# edge = 'carbon'\n",
    "# intensity_type = 'corr'\n",
    "# pol = 0\n",
    "# qlims = (0.01, 0.08)\n",
    "# chi_width = 30\n",
    "\n",
    "# para_DA, perp_DA = make_para_perp_DAs(polar_DS, sample_name, intensity_type, pol, qlims, chi_width)  \n",
    "\n",
    "# # slice ISI data\n",
    "# para_ISI = para_DA.interpolate_na(dim='q').mean('chi').sum('q')\n",
    "# perp_ISI = perp_DA.interpolate_na(dim='q').mean('chi').sum('q')\n",
    "\n",
    "# # plot\n",
    "# fig, ax = plt.subplots()\n",
    "# para_ISI.sel(energy=slice(280,290)).plot.line(ax=ax, label='para', yscale='log')\n",
    "# perp_ISI.sel(energy=slice(280,290)).plot.line(ax=ax, label='perp', yscale='log')\n",
    "# fig.suptitle('Integrated Scattering Intensity (ISI)', fontsize=14)\n",
    "# ax.set(title=f'{sample_name}, Polarization = {pol}°, Chi Width = {chi_width}°', xlabel='Photon Energy [eV]', ylabel='Double-Norm-Corrected Intensity [arb. units]')\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # polar_sample_DS = polar_DS_sample_rows[0]\n",
    "# for polar_sample_DS in tqdm(polar_DS_sample_rows):\n",
    "#     # display(polar_sample_DS)\n",
    "#     sample_name = polar_sample_DS.sample_name.values[0]\n",
    "#     print(sample_name)\n",
    "#     polar_sample_DS.to_netcdf(zarrsPath.joinpath('polar_rsoxs_carbon_ncs', f'{sample_name}.nc'), format='netCDF4', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_DS = polar_DS.chunk({'sample_name':1, 'energy':56, 'polarization':2})\n",
    "\n",
    "polar_DS['samp_diode'] = DS['samp_diode']\n",
    "polar_DS['smoothed_diode'] = DS['smoothed_diode']\n",
    "\n",
    "\n",
    "polar_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = polar_DS.sample_name.values\n",
    "\n",
    "polar_DS.sel(sample_name=[sample_names[0]]).to_zarr(zarrsPath.joinpath(f'polar_{polar_DS.name}_rechunked-v2.zarr'), mode='w')\n",
    "\n",
    "for sample_name in tqdm(sample_names[1:], desc='Samples...'):\n",
    "    polar_DS.sel(sample_name=[sample_name]).to_zarr(zarrsPath.joinpath(f'polar_{polar_DS.name}_rechunked-v2.zarr'), mode='a', append_dim='sample_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_paths = str(zarrsPath.joinpath('polar_rsoxs_carbon_ncs')) + '/*.nc'\n",
    "netcdf_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_DS = xr.open_mfdataset(netcdf_paths)\n",
    "polar_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_DS.sample_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make selection\n",
    "sample_name = 'PM6_CB_3000'\n",
    "edge = 'carbon'\n",
    "intensity_type = 'corr'\n",
    "pol = 0\n",
    "qlims = (0.01, 0.08)\n",
    "chi_width = 90\n",
    "\n",
    "para_DA, perp_DA = make_para_perp_DAs(polar_DS, sample_name, intensity_type, pol, qlims, chi_width)   \n",
    "\n",
    "# Select AR data\n",
    "ar_DA = (para_DA.mean('chi') - perp_DA.mean('chi')) / (para_DA.mean('chi') + perp_DA.mean('chi'))\n",
    "\n",
    "# Plot\n",
    "ax = ar_DA.sel(energy=slice(282,292)).plot(figsize=(8,5), norm=plt.Normalize(-0.6,0.6))\n",
    "ax.figure.suptitle('Anisotropy Ratio (AR) Map', fontsize=14, x=0.43)\n",
    "ax.axes.set(title=f'{sample_name}, Polarization = {pol}°, Chi Width = {chi_width}°', ylabel='Photon Energy [eV]', xlabel='q [$Å^{-1}$]')\n",
    "ax.colorbar.set_label('AR [arb. units]', rotation=270, labelpad=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(polar_DS.sample_name.values)\n",
    "# sample_name = 'PM6-Y6_3000_dSiN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy = 285\n",
    "# energy = 400\n",
    "# energy = 530\n",
    "for sample_name in polar_DS.sample_name.values:\n",
    "    polar_DS['corr_intensity'].sel(sample_name=sample_name, polarization=90, q=slice(0,0.1)).sel(\n",
    "        energy=energy, method='nearest').plot.imshow(norm=LogNorm(2e9, 1e11), cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Get energy values\n",
    "energy_values = polar_DS.energy.values\n",
    "energy_slices = [energy_values[i:i+5] for i in range(0, len(energy_values), 5)]\n",
    "energy_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "polar_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked_polar_DS = polar_DS.stack(system=('sample_name', 'polarization')).reset_index('system')\n",
    "stacked_polar_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the first part of the dataset to initialize the Zarr store\n",
    "first_system = stacked_polar_DS.isel(system=slice(0, 1))\n",
    "first_system.to_zarr(zarrsPath.joinpath(f'polar_{polar_DS.name}.zarr'), mode='w')\n",
    "\n",
    "# Iterate over the rest of the systems and append to the Zarr store\n",
    "for i in tqdm(range(1, len(stacked_polar_DS.system)), desc='Samples...'):\n",
    "    subset = stacked_polar_DS.isel(system=slice(i, i+1))\n",
    "    subset.to_zarr(zarrsPath.joinpath(f'polar_{polar_DS.name}.zarr'), mode='a', append_dim='system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_names = polar_DS.sample_name.values\n",
    "\n",
    "polar_DS.sel(sample_name=[sample_names[0]], polarization=[0]).to_zarr(zarrsPath.joinpath(f'polar_{polar_DS.name}.zarr'), mode='w')\n",
    "\n",
    "for sample_name in tqdm(sample_names[1:], desc='Samples...'):\n",
    "    # polar_DS.sel(sample_name=[sample_name], polarization=[0]).to_zarr(zarrsPath.joinpath(f'polar_{polar_DS.name}.zarr'), mode='a', append_dim='sample_name')\n",
    "    polar_DS.sel(sample_name=[sample_name], polarization=[90]).to_zarr(zarrsPath.joinpath(f'polar_{polar_DS.name}.zarr'), mode='a', append_dim='polarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import zarr\n",
    "\n",
    "# # sample_names = polar_DS.sample_name.values\n",
    "# # energy_values = polar_DS.energy.values\n",
    "# # energy_slices = [energy_values[i:i+5] for i in range(0, len(energy_values), 5)]\n",
    "\n",
    "# # root_store = zarr.open_group(zarrsPath.joinpath(f'polar_{polar_DS.name}_regions.zarr').as_posix(), mode='a')\n",
    "\n",
    "# # for sample in sample_names:\n",
    "# #     # Make sure there's a group for this sample in the Zarr store\n",
    "# #     if sample not in root_store.group_keys():\n",
    "# #         root_store.create_group(sample)\n",
    "    \n",
    "# #     subset_by_sample = polar_DS.sel(sample_name=sample)\n",
    "    \n",
    "# #     for idx, energy_slice in enumerate(energy_slices):\n",
    "# #         final_subset = subset_by_sample.sel(energy=energy_slice)\n",
    "        \n",
    "# #         # Save to the specific group and energy slice within the Zarr store\n",
    "# #         final_subset.to_zarr(root_store[sample], mode='a', append_dim='energy', consolidated=True)\n",
    "\n",
    "# sample_names = polar_DS.sample_name.values\n",
    "# energy_values = polar_DS.energy.values\n",
    "# energy_slices = [energy_values[i:i+5] for i in range(0, len(energy_values), 5)]\n",
    "\n",
    "# main_zarr_path = zarrsPath.joinpath(f'polar_{polar_DS.name}_regions.zarr')\n",
    "\n",
    "# for sample in tqdm(sample_names, desc='Samples...'):\n",
    "#     subset_by_sample = polar_DS.sel(sample_name=sample)\n",
    "    \n",
    "#     # Define path for the sample within the main Zarr store\n",
    "#     sample_path = main_zarr_path.joinpath(sample)\n",
    "    \n",
    "#     for idx, energy_slice in enumerate(energy_slices):\n",
    "#         final_subset = subset_by_sample.sel(energy=energy_slice)\n",
    "        \n",
    "#         # Save to the specific sample path and energy slice within the Zarr store\n",
    "#         if idx==0:\n",
    "#             final_subset.to_zarr(sample_path, mode='w', consolidated=True)\n",
    "#         else:\n",
    "#             final_subset.to_zarr(sample_path, mode='a', append_dim='energy', consolidated=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_para_perp_DAs(datasets, sample_name, edge, intensity_type, pol, qlims, chi_width):\n",
    "    # select dataarray to plot\n",
    "    DS = datasets[f'polar_{edge}']\n",
    "    DA = DS.sel(sample_name=sample_name)[f'{intensity_type}_intensity']\n",
    "    sliced_DA = DA.sel(polarization=pol, q=slice(qlims[0],qlims[1]))\n",
    "\n",
    "    # calculate ISI dataarrays\n",
    "    if pol==0:\n",
    "        para_DA = sliced_DA.rsoxs.slice_chi(180, chi_width=(chi_width/2))\n",
    "        perp_DA = sliced_DA.rsoxs.slice_chi(90, chi_width=(chi_width/2))\n",
    "    elif pol==90:\n",
    "        perp_DA = sliced_DA.rsoxs.slice_chi(180, chi_width=(chi_width/2))\n",
    "        para_DA = sliced_DA.rsoxs.slice_chi(90, chi_width=(chi_width/2))   \n",
    "        \n",
    "    return para_DA, perp_DA\n",
    "\n",
    "# load dictionary of rsoxs datasets\n",
    "rsoxs_datasets = {}\n",
    "key = 'polar_regions'\n",
    "key_start = key.split('_')[0]\n",
    "key_end = key.split('_')[1]        \n",
    "zarrPath = list(zarrsPath.glob(f'{key_start}*{key_end}.zarr'))[0]\n",
    "rsoxs_datasets[key] = xr.open_zarr(zarrPath)\n",
    "\n",
    "# Compute any dask coordiantes\n",
    "for coord_name, coord_data in rsoxs_datasets[key].coords.items():\n",
    "    if isinstance(coord_data.data, da.Array):\n",
    "        rsoxs_datasets[key].coords[coord_name] = coord_data.compute()\n",
    "            \n",
    "rsoxs_datasets[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make selection\n",
    "edge = 'regions'\n",
    "intensity_type = 'corr'\n",
    "qlims = (0.01, 0.08)\n",
    "chi_width = 30\n",
    "\n",
    "for sample_name in tqdm(rsoxs_datasets[f'polar_{edge}'].sample_name.data):\n",
    "    for pol in [0, 90]:\n",
    "        ### Select para & perp DataArrays\n",
    "        para_DA, perp_DA = make_para_perp_DAs(rsoxs_datasets, sample_name, edge, intensity_type, pol, qlims, chi_width)  \n",
    "        \n",
    "#         ### ISI:\n",
    "#         # Slice ISI data\n",
    "#         para_ISI = para_DA.interpolate_na(dim='q').mean('chi').sum('q')\n",
    "#         perp_ISI = perp_DA.interpolate_na(dim='q').mean('chi').sum('q')\n",
    "\n",
    "#         # Plot\n",
    "#         fig, ax = plt.subplots()\n",
    "#         para_ISI.sel(energy=slice(280,290)).plot.line(ax=ax, label='para', yscale='log')\n",
    "#         perp_ISI.sel(energy=slice(280,290)).plot.line(ax=ax, label='perp', yscale='log')\n",
    "#         fig.suptitle('Integrated Scattering Intensity (ISI)', fontsize=14)\n",
    "#         ax.set(title=f'{sample_name}, Polarization = {pol}°, Chi Width = {chi_width}°', xlabel='Photon Energy [eV]', ylabel='Double-Norm-Corrected Intensity [arb. units]')\n",
    "#         ax.legend()\n",
    "#         fig.savefig(plotsPath.joinpath('isi', f'{sample_name}_{edge}_{intensity_type}_chiWidth-{chi_width}deg_pol{pol}deg.png'), dpi=120)\n",
    "#         plt.close('all')\n",
    "        \n",
    "#         ### Linecut Maps:\n",
    "#         fig, axs = plt.subplots(1, 2, figsize=(11,5))\n",
    "\n",
    "#         para_DA.mean('chi').sel(energy=slice(282,290)).plot(ax=axs[0], cmap=cmap, norm=LogNorm(1e9, 1e11), add_colorbar=False)\n",
    "#         perp_DA.mean('chi').sel(energy=slice(282,290)).plot(ax=axs[1], cmap=cmap, norm=LogNorm(1e9, 1e11), add_colorbar=False)\n",
    "\n",
    "#         sm = plt.cm.ScalarMappable(cmap=cmap, norm=LogNorm(2e10, 1e12)) # Create a ScalarMappable object with the colormap and normalization & add the colorbar to the figure\n",
    "#         cax = axs[1].inset_axes([1.03, 0, 0.05, 1])\n",
    "#         cbar = fig.colorbar(sm, cax=cax, orientation='vertical')\n",
    "#         cbar.set_label(label='Intensity [arb. units]', labelpad=12)\n",
    "#         fig.suptitle(f'Linecut Maps: {sample_name}, Polarization = {pol}°, Chi Width = {chi_width}°', fontsize=14)\n",
    "#         fig.set(tight_layout=True)\n",
    "#         axs[0].set(title='Parallel to $E_p$', ylabel='Photon energy [eV]', xlabel='q [$Å^{-1}$]')\n",
    "#         axs[1].set(title='Perpendicular to $E_p$ ', ylabel=None, xlabel='q [$Å^{-1}$]')\n",
    "#         fig.savefig(plotsPath.joinpath('linecut_maps', f'{sample_name}_{edge}_{intensity_type}_chiWidth-{chi_width}deg_pol{pol}deg.png'), dpi=120)\n",
    "#         plt.close('all')\n",
    "\n",
    "        ### AR Maps:\n",
    "        # Select AR data\n",
    "        ar_DA = (para_DA.mean('chi') - perp_DA.mean('chi')) / (para_DA.mean('chi') + perp_DA.mean('chi'))\n",
    "\n",
    "        # Plot\n",
    "        ax = ar_DA.sel(energy=slice(282,292)).plot(figsize=(8,5), norm=plt.Normalize(-0.6, 0.6))\n",
    "        ax.figure.suptitle('Anisotropy Ratio (AR) Map', fontsize=14, x=0.43)\n",
    "        ax.axes.set(title=f'{sample_name}, Polarization = {pol}°, Chi Width = {chi_width}°', ylabel='Photon Energy [eV]', xlabel='q [$Å^{-1}$]')\n",
    "        ax.colorbar.set_label('AR [arb. units]', rotation=270, labelpad=12)\n",
    "        # ax.figure.savefig(plotsPath.joinpath('ar_maps', f'{sample_name}_{edge}_{intensity_type}_chiWidth-{chi_width}deg_pol{pol}deg.png'), dpi=120)\n",
    "        plt.show()\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Quick DataArray contents checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy = 2477\n",
    "\n",
    "sliced_DA = recip_DA.squeeze().sel(energy=energy, method='nearest')\n",
    "\n",
    "cmin = sliced_DA.compute().quantile(0.15)\n",
    "cmax = sliced_DA.compute().quantile(0.995)\n",
    "ax = sliced_DA.plot.imshow(norm=plt.Normalize(cmin, cmax), cmap=plt.cm.turbo, x='q_x', y='q_y')\n",
    "# ax.axes.set(title=f'{sample_name}: Energy = {energy}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "swap_caked_DA = caked_DA.swap_dims({'index_x':'q_r', 'index_y':'chi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy = 2477\n",
    "\n",
    "sliced_DA = swap_caked_DA.squeeze().sel(energy=energy, method='nearest')\n",
    "\n",
    "cmin = sliced_DA.compute().quantile(0.15)\n",
    "cmax = sliced_DA.compute().quantile(0.995)\n",
    "ax = sliced_DA.plot.imshow(norm=plt.Normalize(cmin, cmax), cmap=plt.cm.turbo, xscale='log')\n",
    "# ax.axes.set(title=f'{sample_name}: Energy = {energy}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Misc cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trmsn_35_tot = sorted(reducedPath.glob('*tot*Trmsn_35*.txt'))\n",
    "# trmsn_35_ver = sorted(reducedPath.glob('*ver*Trmsn_35*.txt'))\n",
    "# trmsn_35_hor = sorted(reducedPath.glob('*hor*Trmsn_35*.txt'))\n",
    "\n",
    "# len([f.name for f in trmsn_35_tot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for file in trmsn_35_tot:\n",
    "#     pr = np.loadtxt(file)\n",
    "#     plt.plot(pr[:, 1]-0.9*np.mean(pr[1100:1250, 1]))\n",
    "#     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
